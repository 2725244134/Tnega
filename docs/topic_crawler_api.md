# ä¸»é¢˜æŠ“å– API ç²¾ç®€ç‰ˆ

## âœ… æ ¸å¿ƒèƒ½åŠ›

TwitterCrawler é¢å‘ä¸»é¢˜æŠ“å–ï¼Œæä¾›å¼‚æ­¥ API å’Œç±»å‹å®‰å…¨æ¨¡å‹ï¼Œæ”¯æŒå†å²å›å¡«ä¸å®æ—¶ç›‘æ§ã€‚

---

## ğŸ¯ æ ¸å¿ƒ API

### 1. `search_all_tweets()` - å®Œæ•´å†å²æœç´¢ ğŸ”¥

**ç”¨é€”**ï¼šæœç´¢æŒ‡å®šä¸»é¢˜çš„å®Œæ•´æ¨æ–‡å†å²ï¼ˆä» 2006 å¹´å¼€å§‹ï¼‰

```python
results = await crawler.search_all_tweets(
    query="AI agents",
    max_results=500,
    start_time="2023-01-01T00:00:00Z",
    end_time="2023-12-31T23:59:59Z"
)

# æ”¯æŒåˆ†é¡µ
next_page = await crawler.search_all_tweets(
    query="AI agents",
    max_results=500,
    next_token=results.next_token  # è·å–ä¸‹ä¸€é¡µ
)
```

**é™åˆ¶**ï¼š
- éœ€è¦ **Academic Research** æƒé™
- å•æ¬¡æœ€å¤š 500 æ¡
- é»˜è®¤è¿”å›æœ€è¿‘ 30 å¤©ï¼ˆå¦‚ä¸æŒ‡å®š `start_time`ï¼‰

---

### 1.1 `search_all_tweets_paginated()` - è‡ªåŠ¨åˆ†é¡µå›å¡« ğŸ—‚ï¸

**ç”¨é€”**ï¼šè‡ªåŠ¨å¤„ç† `next_token`ï¼Œå¸¦é€Ÿç‡é™åˆ¶é€€é¿ï¼Œæ±‡æ€»å¤šé¡µç»“æœå¹¶è¡¥å……æœç´¢å…ƒæ•°æ®ã€‚

```python
results = await crawler.search_all_tweets_paginated(
    query='(Ø§Ù„ØµÙŠÙ† OR Ø¨ÙƒÙŠÙ†) "Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠ"',
    start_time="2025-01-01T00:00:00Z",
    end_time="2025-01-31T23:59:59Z",
    max_results=400,
    page_pause=3.5,
    label="parade2025_ar_window",
    language="ar",
)

print(results.metadata.page_count)      # åˆ†é¡µæ¬¡æ•°
print(results.metadata.total_collected) # åˆå¹¶åçš„æ¨æ–‡é‡
```

**ç‰¹ç‚¹**ï¼š
- âœ… è‡ªåŠ¨è¿½åŠ  `lang:<code>` è¿‡æ»¤ï¼ˆå¦‚æä¾› `language="ar"`ï¼‰
- âœ… æŒ‡æ•°é€€é¿å¤„ç† `TooManyRequests`
- âœ… å…ƒæ•°æ®åŒ…å«æ—¶é—´çª—å£ã€åˆ†é¡µæ¬¡æ•°ã€ä¿å­˜æ ‡ç­¾

---

### 2. `get_tweet()` - è·å–å•æ¡æ¨æ–‡è¯¦æƒ…

**ç”¨é€”**ï¼šæŸ¥çœ‹ç‰¹å®šæ¨æ–‡çš„å®Œæ•´ä¿¡æ¯ï¼ˆåŒ…å«å¼•ç”¨/è¯„è®ºå…³ç³»ï¼‰

```python
tweet = await crawler.get_tweet("1234567890")

print(f"å†…å®¹: {tweet.text}")
print(f"ç‚¹èµ: {tweet.like_count:,}")
print(f"è½¬å‘: {tweet.retweet_count:,}")

# æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤
if tweet.referenced_tweets:
    print(f"å¼•ç”¨äº†å…¶ä»–æ¨æ–‡")
```

**é€‚ç”¨åœºæ™¯**ï¼š
- æ·±æŒ–çƒ­é—¨æ¨æ–‡
- è·å–æœç´¢ç»“æœä¸­å¼•ç”¨çš„æ¨æ–‡è¯¦æƒ…

---

### 3. `search_recent_tweets()` - æœ€è¿‘ 7 å¤©æœç´¢

```python
results = await crawler.search_recent_tweets(
    query="China military parade lang:ar",
    max_results=50,
)

print(results.metadata.source)  # "search_recent"
```

**é€‚ç”¨åœºæ™¯**ï¼šå¿«é€ŸéªŒè¯æŸ¥è¯¢è¯æˆ–ç›‘æ§æœ€æ–°åŠ¨æ€ã€‚

---

### 3. `get_tweets()` - æ‰¹é‡è·å–æ¨æ–‡

**ç”¨é€”**ï¼šä¸€æ¬¡æ€§è·å–å¤šæ¡æ¨æ–‡ï¼ˆæœ€å¤š 100 æ¡ï¼‰

```python
# æ‰¹é‡è·å–
results = await crawler.get_tweets([
    "1234567890",
    "0987654321",
    "5555555555"
])

# è¿”å› SearchResultsï¼ˆåŒ…å«æ¨æ–‡ + ç”¨æˆ·æ˜ å°„ï¼‰
for tweet in results.tweets:
    author = results.users.get(tweet.author_id)
    print(f"@{author.username}: {tweet.text[:50]}...")
```

**é€‚ç”¨åœºæ™¯**ï¼š
- è·å–æœç´¢ç»“æœä¸­æåˆ°çš„æ‰€æœ‰å¼•ç”¨æ¨æ–‡
- æ‰¹é‡æŸ¥çœ‹çƒ­é—¨è¯„è®º

---

### 4. `fetch_user_by_id()` - è·å–ç”¨æˆ·ä¿¡æ¯

**ç”¨é€”**ï¼šè·å–æ¨æ–‡ä½œè€…çš„è¯¦ç»†èµ„æ–™

```python
user = await crawler.fetch_user_by_id("12")

print(f"ç”¨æˆ·: @{user.username}")
print(f"ç²‰ä¸: {user.followers_count:,}")
print(f"ç®€ä»‹: {user.description}")
```

**é€‚ç”¨åœºæ™¯**ï¼š
- è¡¥å…¨æœç´¢ç»“æœä¸­çš„ç”¨æˆ·ä¿¡æ¯
- åˆ†ææ¨æ–‡ä½œè€…çš„å½±å“åŠ›

---

## ğŸ”„ å…¸å‹å·¥ä½œæµ

### åœºæ™¯ 1ï¼šæ·±åº¦ä¸»é¢˜åˆ†æ

```python
# 1. æœç´¢ä¸»é¢˜
results = await crawler.search_all_tweets(
    "Web3 developer",
    max_results=500,
    start_time="2024-01-01T00:00:00Z"
)

# 2. è·å–é«˜äº’åŠ¨æ¨æ–‡çš„è¯¦æƒ…
hot_tweets = [t for t in results.tweets if t.like_count > 1000]
details = await crawler.get_tweets([t.id for t in hot_tweets])

# 3. åˆ†æä½œè€…
for tweet in details.tweets:
    author = await crawler.fetch_user_by_id(tweet.author_id)
    print(f"KOL: @{author.username}, ç²‰ä¸ {author.followers_count:,}")
```

### åœºæ™¯ 2ï¼šæŒç»­ç›‘æ§

```python
# æœç´¢æœ€æ–°è®¨è®º
results = await crawler.search_all_tweets(
    "GPT-5 release",
    max_results=100
)

# æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹
if results.next_token:
    # ä¿å­˜ tokenï¼Œä¸‹æ¬¡ä»è¿™é‡Œç»§ç»­
    save_checkpoint(results.next_token)
```

---

## âš ï¸ å·²çŸ¥é™åˆ¶

1. **é€Ÿç‡é™åˆ¶ï¼ˆ429 é”™è¯¯ï¼‰**
   - Twitter API æœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶
   - `search_all_tweets_paginated()` å·²å†…å»ºæŒ‡æ•°é€€é¿ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´ `page_pause`

2. **Academic Research æƒé™**
   - `search_all_tweets()` éœ€è¦ç‰¹æ®Šæƒé™
   - æ™®é€šè´¦å·æ— æ³•è®¿é—®å®Œæ•´å†å²

3. **æ•°æ®å®Œæ•´æ€§**
   - æŸäº›å­—æ®µå¯èƒ½ä¸º `None`ï¼ˆå–å†³äº API è¿”å›ï¼‰
   - éœ€è¦åœ¨ä½¿ç”¨å‰æ£€æŸ¥

---

## ğŸ“ æµ‹è¯•çŠ¶æ€

```bash
$ uv run python tests/test_topic_crawler.py

âœ… get_tweet() - æˆåŠŸè·å–æ¨æ–‡è¯¦æƒ…
âœ… get_tweets() - æ‰¹é‡è·å– 2 æ¡æ¨æ–‡
âš ï¸ fetch_user_by_id() - è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼ˆ429ï¼‰
âš ï¸ search_all_tweets() - éœ€è¦ Academic Research æƒé™
```

**ç»“è®º**ï¼šæ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ï¼Œéœ€è¦å¤„ç†é€Ÿç‡é™åˆ¶å’Œæƒé™é—®é¢˜ã€‚
