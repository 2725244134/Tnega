# Twitter Crawler ä½¿ç”¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

```python
import asyncio
from src.x_crawl import TwitterCrawler

async def main():
    # åˆå§‹åŒ– crawlerï¼ˆè‡ªåŠ¨ä» .env åŠ è½½ bearer_tokenï¼‰
    crawler = TwitterCrawler()
    
    try:
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user = await crawler.fetch_user_by_username("jack")
        print(f"ç”¨æˆ·ï¼š@{user.username}")
        print(f"ç²‰ä¸æ•°ï¼š{user.followers_count:,}")
        
        # è·å–ç”¨æˆ·æ—¶é—´çº¿
        timeline = await crawler.fetch_user_timeline(user.id, max_results=10)
        print(f"\næœ€è¿‘æ¨æ–‡æ•°ï¼š{timeline.result_count}")
        
        for tweet in timeline.tweets[:3]:
            print(f"- {tweet.text[:60]}...")
        
        # æœç´¢æ¨æ–‡
        results = await crawler.search_recent_tweets("python AI", max_results=10)
        print(f"\næœç´¢åˆ° {results.result_count} æ¡æ¨æ–‡")
        
    finally:
        await crawler.close()

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ“‹ API æ–¹æ³•

### ç”¨æˆ·ç›¸å…³

```python
# æ ¹æ®ç”¨æˆ·åè·å–ç”¨æˆ·
user = await crawler.fetch_user_by_username("jack")

# æ ¹æ® ID è·å–ç”¨æˆ·
user = await crawler.fetch_user_by_id("12")
```

### æ¨æ–‡ç›¸å…³

```python
# è·å–å•æ¡æ¨æ–‡
tweet = await crawler.fetch_tweet_by_id("20")

# è·å–ç”¨æˆ·æ—¶é—´çº¿
timeline = await crawler.fetch_user_timeline("12", max_results=20)

# æœç´¢æ¨æ–‡
results = await crawler.search_recent_tweets("python", max_results=50)
```

## ğŸ¯ è¿”å›ç±»å‹

æ‰€æœ‰æ–¹æ³•éƒ½è¿”å›ç±»å‹å®‰å…¨çš„ Pydantic æ¨¡å‹ï¼š

- `User` - ç”¨æˆ·ä¿¡æ¯ï¼ˆåŒ…å«ç²‰ä¸æ•°ã€è®¤è¯çŠ¶æ€ç­‰ï¼‰
- `Tweet` - æ¨æ–‡å¯¹è±¡ï¼ˆæ–‡æœ¬ã€äº’åŠ¨æ•°æ®ã€æ—¶é—´ç­‰ï¼‰
- `Timeline` - æ—¶é—´çº¿å®¹å™¨ï¼ˆæ¨æ–‡åˆ—è¡¨ + ç”¨æˆ·æ˜ å°„ + åˆ†é¡µä¿¡æ¯ï¼‰
- `SearchResults` - æœç´¢ç»“æœå®¹å™¨ï¼ˆæ¨æ–‡åˆ—è¡¨ + åˆ†é¡µä»¤ç‰Œï¼‰

## âš™ï¸ é…ç½®

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```properties
"bearer_token" = "ä½ çš„ Twitter Bearer Token"
```

æˆ–åœ¨ä»£ç ä¸­ç›´æ¥ä¼ å…¥ï¼š

```python
crawler = TwitterCrawler(bearer_token="YOUR_TOKEN_HERE")
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆéœ€è¦æœ‰æ•ˆçš„ API å‡­è¯ï¼‰
uv run python tests/test_crawler.py

# æˆ–ä½¿ç”¨ pytest
uv run pytest tests/test_crawler.py -v
```

## ğŸ“Š æµ‹è¯•ç»“æœç¤ºä¾‹

```
âœ… é€šè¿‡ï¼š5 | âŒ å¤±è´¥ï¼š0

æµ‹è¯•å†…å®¹ï¼š
- è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆç”¨æˆ·åï¼‰âœ…
- è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆIDï¼‰âœ…
- è·å–å•æ¡æ¨æ–‡ âœ…
- è·å–ç”¨æˆ·æ—¶é—´çº¿ âœ…
- æœç´¢æ¨æ–‡ âœ…
```

## ğŸ¨ è®¾è®¡åŸåˆ™

- **å…¨å¼‚æ­¥**ï¼šæ‰€æœ‰ API è°ƒç”¨éƒ½æ˜¯å¼‚æ­¥çš„
- **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®
- **æ—¥å¿—å‹å¥½**ï¼šä½¿ç”¨ loguru è®°å½•æ‰€æœ‰å…³é”®æ“ä½œ
- **ç®€æ´ä¼˜é›…**ï¼šAPI è®¾è®¡ç›´è§‚ï¼Œç¬¦åˆ Python ä¹ æƒ¯
