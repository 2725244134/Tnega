"""
============================================
ä¸»é¢˜æŠ“å– API æµ‹è¯•
============================================
æµ‹è¯•é¢å‘ä¸»é¢˜æŠ“å–çš„æ ¸å¿ƒ API
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.x_crawl import TwitterCrawler


async def test_search_all_tweets():
    """æµ‹è¯•å®Œæ•´å†å²æœç´¢ï¼ˆéœ€è¦ Academic Research æƒé™ï¼‰"""
    print("\nâ–¶ï¸ æµ‹è¯•ï¼šæœç´¢å®Œæ•´å†å²æ¨æ–‡")
    
    crawler = TwitterCrawler()
    
    try:
        # æœç´¢å…³äº "python" çš„æ¨æ–‡ï¼ˆè¿‡å» 30 å¤©ï¼‰
        results = await crawler.search_all_tweets(
            query="python",
            max_results=10
        )
        
        print(f"âœ… æœç´¢ç»“æœï¼š{results.result_count} æ¡æ¨æ–‡")
        
        if results.tweets:
            first = results.tweets[0]
            print(f"   ç¤ºä¾‹æ¨æ–‡: {first.text[:60]}...")
            
        if results.next_token:
            print(f"   ä¸‹ä¸€é¡µä»¤ç‰Œ: {results.next_token[:30]}...")
        
    except Exception as e:
        print(f"âš ï¸ æœç´¢å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦ Academic Research æƒé™ï¼‰: {e}")
    
    finally:
        await crawler.close()


async def test_get_tweet():
    """æµ‹è¯•è·å–å•æ¡æ¨æ–‡è¯¦æƒ…"""
    print("\nâ–¶ï¸ æµ‹è¯•ï¼šè·å–æ¨æ–‡è¯¦æƒ…")
    
    crawler = TwitterCrawler()
    
    try:
        # è·å– Twitter ç¬¬ä¸€æ¡æ¨æ–‡
        tweet = await crawler.get_tweet("20")
        
        print(f"âœ… æ¨æ–‡å†…å®¹: {tweet.text}")
        print(f"   ç‚¹èµ: {tweet.like_count:,}, è½¬å‘: {tweet.retweet_count:,}")
        
    finally:
        await crawler.close()


async def test_get_tweets_batch():
    """æµ‹è¯•æ‰¹é‡è·å–æ¨æ–‡"""
    print("\nâ–¶ï¸ æµ‹è¯•ï¼šæ‰¹é‡è·å–æ¨æ–‡")
    
    crawler = TwitterCrawler()
    
    try:
        # æ‰¹é‡è·å–å¤šæ¡æ¨æ–‡
        results = await crawler.get_tweets([
            "20",  # Twitter ç¬¬ä¸€æ¡æ¨æ–‡
            "21",  # ç¬¬äºŒæ¡æ¨æ–‡
        ])
        
        print(f"âœ… è·å–åˆ° {results.result_count} æ¡æ¨æ–‡")
        
        for tweet in results.tweets:
            print(f"   - {tweet.text[:50]}...")
        
    finally:
        await crawler.close()


async def test_fetch_user_by_id():
    """æµ‹è¯•è·å–ç”¨æˆ·ä¿¡æ¯"""
    print("\nâ–¶ï¸ æµ‹è¯•ï¼šè·å–ç”¨æˆ·ä¿¡æ¯")
    
    crawler = TwitterCrawler()
    
    try:
        # è·å– Jack Dorsey çš„ç”¨æˆ·ä¿¡æ¯
        user = await crawler.fetch_user_by_id("12")
        
        print(f"âœ… ç”¨æˆ·: @{user.username}")
        print(f"   ç²‰ä¸æ•°: {user.followers_count:,}")
        
    except Exception as e:
        print(f"âš ï¸ è·å–å¤±è´¥ï¼ˆå¯èƒ½è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼‰: {e}")
        
    finally:
        await crawler.close()


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ§ª ä¸»é¢˜æŠ“å– API æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æ ¸å¿ƒ API
    await test_get_tweet()
    await test_get_tweets_batch()
    await test_fetch_user_by_id()
    await test_search_all_tweets()  # å¯èƒ½å¤±è´¥ï¼ˆéœ€è¦ç‰¹æ®Šæƒé™ï¼‰
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
